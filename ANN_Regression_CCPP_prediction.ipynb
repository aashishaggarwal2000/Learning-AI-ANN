{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Regression_CCPP_prediction",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashishaggarwal2000/Learning-AI-ANN/blob/main/ANN_Regression_CCPP_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbb7fRy-eyr"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sNDnxE2-pwE"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFK-Fv8oxKJo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AxsLSNyvx5m8",
        "outputId": "0102b17e-a3e9-400a-ce1d-8ac14bd5eccc"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG3FQEch-yuA"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4zq8Mza_D9O"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cENUUoo13QK5"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Jw9vk9zy8e"
      },
      "source": [
        "dataset = pd.read_excel('Folds5x2_pp.xlsx')\n",
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyOHC9DB4PBY",
        "outputId": "2ab76aa5-280c-4b9d-86c8-f16f374c3805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  14.96   41.76 1024.07   73.17]\n",
            " [  25.18   62.96 1020.04   59.08]\n",
            " [   5.11   39.4  1012.16   92.14]\n",
            " ...\n",
            " [  31.32   74.33 1012.92   36.48]\n",
            " [  24.48   69.45 1013.86   62.39]\n",
            " [  21.6    62.52 1017.23   67.87]]\n",
            "[463.26 444.37 488.56 ... 429.57 435.74 453.28]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7awqCsP168O"
      },
      "source": [
        "The dataset would be retrieved using the pandas library and then we need to devide the full dataset into a matrix and a dependent variable vector.\n",
        "Matrix would contains all the feature observations and vector would contain only the actual result column which is elctrical power generated as an output.\n",
        "\n",
        "The matrix is being extracted using iLoc function of Pandas which allows to filter all the rows and columns based upon 2 params. We are keeping first param as empty range \":\" to select all the rows and second param as the :-1 which selects column0 to second last column. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC6omXel_Up0"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsk-NeG94s4_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe3l2Igg6iRd"
      },
      "source": [
        "Here we need to split the whole dataset into training and test set. Usually it is kept at 80 to 20 ratio. Python provide us the easy way to sptil this training/test set directly from the feature matrix x and dependent variable y created above. we just need to import the train_test_split function from the sklearn.model_selection library.\n",
        "Here random state is set to 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mSLlAT9_eyI"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsBULd_f_wLY"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4alLZvn7MAm"
      },
      "source": [
        "ann = tf.keras.models.Sequential() "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPBOcgaC84wk"
      },
      "source": [
        "In order to build an artificial neural network model we need to instantiate an object of the sequenctial class from tensorflow and karas library. \n",
        "**Keras is kind of wrapper library imbedded in the tensorflow which simplifies the usage of tensorflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iitAFJS_ABUn"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuTnbTzV_UDr"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKravjgTCras"
      },
      "source": [
        "Here we don't need to specify the input layer as it would be automatically detected by tensorflow from the injected feature matrix. We directly define the first hidden layer with 2 params: unit = number of neural nodes we need on this layer and activation = function need to be applied on each node which is usually the rectified linear function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lb4kK_wAKbs"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug0YCt8nDsjs"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWJmKq-mW9Io"
      },
      "source": [
        "This will be done similar to the first hidden layer added above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwMOmKb3AdBY"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhzEwIziWK4l"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9mcYtp8XEeH"
      },
      "source": [
        "The output layer is most important part which has only one node, so units=1. The other params like activation function is not requierd for regression ann model however we can select segmoid or soft-max functions for the binary or multiclass classification models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq7e4fF6A1yy"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDeylAs2An25"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4WDJCLoZeEe"
      },
      "source": [
        "ann.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV1XPCxlZxMt"
      },
      "source": [
        "When the sequential model is defined having all the layers (input, hidden and output layers). The next step is to compile the model while specifying the optimizer alogorithm='adam' which is very good for stochastic gredient decent technique of weight adjustment backpropagation and second param is loss=mse to calculate the loss function need to be optimized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjVuiybYOo7r"
      },
      "source": [
        "### Training the ANN model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekj7cjXXbSsI"
      },
      "source": [
        "ann.fit(x_train, y_train, batch_size=32, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H0zKKNEBLD5"
      },
      "source": [
        "### Predicting the results of the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7iUui5wfAPL",
        "outputId": "214f0998-5e0a-4523-c7e0-c3f77ca32e29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = ann.predict(x_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(y_pred)\n",
        "y1= np.concatenate((y_test.reshape(len(y_test),1),y_pred),1) \n",
        "print(y1)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[430.23]\n",
            " [461.34]\n",
            " [464.88]\n",
            " ...\n",
            " [472.03]\n",
            " [438.98]\n",
            " [458.13]]\n",
            "[[431.23 430.23]\n",
            " [460.01 461.34]\n",
            " [461.14 464.88]\n",
            " ...\n",
            " [473.26 472.03]\n",
            " [438.   438.98]\n",
            " [463.28 458.13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wfSTzIblM0K"
      },
      "source": [
        "Now comes the prediction part as our first regression artificial neural network model is ready to predict the unseen data.\n",
        "For prediction we just need to pass the x_train feature set having 20% of the records splitted from orginial dataset initally.\n",
        "\n",
        "There are cool numpy funtions which can be applied to show the predicted value with 2 digit precision.\n",
        "\n",
        "The normal output y_prid would appear as vertical vector however we want to represent the data in the form of 2 vertical columns arranged side by side showing the actual value and predicted value.\n",
        "\n",
        "Bit tricky as y_test vector is horizontal and we need to first reshape that "
      ]
    }
  ]
}
